{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61701eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base Station 1, Epoch 1\n",
      "Training Base Station 1, Epoch 2\n",
      "Training Base Station 1, Epoch 3\n",
      "Training Base Station 1, Epoch 4\n",
      "Training Base Station 1, Epoch 5\n",
      "Training Base Station 1, Epoch 6\n",
      "Training Base Station 1, Epoch 7\n",
      "Training Base Station 1, Epoch 8\n",
      "Training Base Station 1, Epoch 9\n",
      "Training Base Station 1, Epoch 10\n",
      "Training Base Station 1, Epoch 11\n",
      "Training Base Station 1, Epoch 12\n",
      "Training Base Station 1, Epoch 13\n",
      "Training Base Station 1, Epoch 14\n",
      "Training Base Station 1, Epoch 15\n",
      "Training Base Station 1, Epoch 16\n",
      "Training Base Station 1, Epoch 17\n",
      "Training Base Station 1, Epoch 18\n",
      "Training Base Station 1, Epoch 19\n",
      "Training Base Station 1, Epoch 20\n",
      "Training Base Station 1, Epoch 21\n",
      "Training Base Station 1, Epoch 22\n",
      "Training Base Station 1, Epoch 23\n",
      "Training Base Station 1, Epoch 24\n",
      "Training Base Station 1, Epoch 25\n",
      "Training Base Station 1, Epoch 26\n",
      "Training Base Station 1, Epoch 27\n",
      "Training Base Station 1, Epoch 28\n",
      "Training Base Station 1, Epoch 29\n",
      "Training Base Station 1, Epoch 30\n",
      "Training Base Station 1, Epoch 31\n",
      "Training Base Station 1, Epoch 32\n",
      "Training Base Station 1, Epoch 33\n",
      "Training Base Station 1, Epoch 34\n",
      "Training Base Station 1, Epoch 35\n",
      "Training Base Station 1, Epoch 36\n",
      "Training Base Station 1, Epoch 37\n",
      "Training Base Station 1, Epoch 38\n",
      "Training Base Station 1, Epoch 39\n",
      "Training Base Station 1, Epoch 40\n",
      "Training Base Station 1, Epoch 41\n",
      "Training Base Station 1, Epoch 42\n",
      "Training Base Station 1, Epoch 43\n",
      "Training Base Station 1, Epoch 44\n",
      "Training Base Station 1, Epoch 45\n",
      "Training Base Station 1, Epoch 46\n",
      "Training Base Station 1, Epoch 47\n",
      "Training Base Station 1, Epoch 48\n",
      "Training Base Station 1, Epoch 49\n",
      "Training Base Station 1, Epoch 50\n",
      "Training Base Station 2, Epoch 1\n",
      "Training Base Station 2, Epoch 2\n",
      "Training Base Station 2, Epoch 3\n",
      "Training Base Station 2, Epoch 4\n",
      "Training Base Station 2, Epoch 5\n",
      "Training Base Station 2, Epoch 6\n",
      "Training Base Station 2, Epoch 7\n",
      "Training Base Station 2, Epoch 8\n",
      "Training Base Station 2, Epoch 9\n",
      "Training Base Station 2, Epoch 10\n",
      "Training Base Station 2, Epoch 11\n",
      "Training Base Station 2, Epoch 12\n",
      "Training Base Station 2, Epoch 13\n",
      "Training Base Station 2, Epoch 14\n",
      "Training Base Station 2, Epoch 15\n",
      "Training Base Station 2, Epoch 16\n",
      "Training Base Station 2, Epoch 17\n",
      "Training Base Station 2, Epoch 18\n",
      "Training Base Station 2, Epoch 19\n",
      "Training Base Station 2, Epoch 20\n",
      "Training Base Station 2, Epoch 21\n",
      "Training Base Station 2, Epoch 22\n",
      "Training Base Station 2, Epoch 23\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from timm.models import create_model\n",
    "\n",
    "# Function to load image data\n",
    "def load_image_data(index, base_station_folder='output_images'):\n",
    "    image_path = f'{base_station_folder}/BS{base_station + 1}/Image_Row_{index + 1}_BS{base_station + 1}.png'\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Convert to tensor\n",
    "    image = torch.tensor(np.array(image), dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "\n",
    "    return image\n",
    "\n",
    "# Loading data\n",
    "Out_set_file = loadmat('DLCB_dataset/O1_60/DLCB_output.mat')\n",
    "Out_set = Out_set_file['DL_output'].astype(np.float32)\n",
    "\n",
    "num_user_tot = 20  # Change this if needed\n",
    "DL_size_ratio = 0.2\n",
    "DL_size = int(num_user_tot * DL_size_ratio)\n",
    "\n",
    "np.random.seed(2016)\n",
    "num_train = int(DL_size * 0.8)\n",
    "num_test = int(num_user_tot * 0.2)\n",
    "num_epochs = 50\n",
    "\n",
    "train_index, test_index = train_test_split(range(num_user_tot), test_size=num_test, random_state=2016)\n",
    "Out_train, Out_test = Out_set[train_index], Out_set[test_index]\n",
    "\n",
    "# Number of base stations\n",
    "num_base_stations = 4\n",
    "training_history = [[] for _ in range(num_base_stations)]\n",
    "# Divide output data into segments for each base station\n",
    "output_segments_train = torch.chunk(torch.tensor(Out_train), num_base_stations, dim=1)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, output_size):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Adjusted input size for the fully connected layer\n",
    "        last_conv_dim = 256 * 8 * 8  # Update this based on the size after the last convolution\n",
    "        self.fc = nn.Linear(last_conv_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the MobileViT model\n",
    "class MobileViTModel(nn.Module):\n",
    "    def __init__(self, input_channels, output_size, pretrained=True):\n",
    "        super(MobileViTModel, self).__init__()\n",
    "\n",
    "        # Load MobileViT model (freeze pre-trained weights by default)\n",
    "        self.mobilevit = create_model('vit_base_patch16_224', pretrained=pretrained)\n",
    "        for param in self.mobilevit.parameters():\n",
    "            param.requires_grad = False  # Freeze pre-trained weights\n",
    "\n",
    "        # Access feature extraction layers based on timm version (replace if necessary)\n",
    "        self.features = self.mobilevit.blocks  # Assuming 'blocks' contains feature extraction layers\n",
    "\n",
    "        # Determine output dimension of MobileViT (might vary depending on the variant)\n",
    "        self.mobilevit_out_features = self.mobilevit.head.in_features  # Assuming 'head' leads to final output\n",
    "\n",
    "        # Add a fully connected layer to reshape the output\n",
    "        self.fc = nn.Linear(self.mobilevit_out_features * 16, output_size)  # Assuming 16 patches\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input tensor to match the expected shape for the MobileViT model\n",
    "        x = x.view(x.size(0), -1, 768)  # Reshape to [batch_size, num_patches, 768]\n",
    "\n",
    "        # Feature extraction using MobileViT\n",
    "        x = self.features(x)\n",
    "\n",
    "        # Flatten the output tensor before passing through the fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Apply the fully connected layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, cnn_model, mobilevit_model, hidden_layer_size, output_size, final_output_size):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.mobilevit_model = mobilevit_model\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.fc2 = nn.Linear(output_size, final_output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through CNN model\n",
    "        cnn_output = self.cnn_model(x)\n",
    "        # Forward pass through MobileViT model\n",
    "        mobilevit_output = self.mobilevit_model(x)\n",
    "\n",
    "        # Combine predictions (you can use any method for aggregation, e.g., averaging)\n",
    "        combined_output = (cnn_output + mobilevit_output) / 2  # Simple average\n",
    "        \n",
    "        # Get the shape of combined_output dynamically\n",
    "        combined_output_shape = combined_output.shape[-1]\n",
    "\n",
    "        # Pass combined_output through additional layers\n",
    "        x = nn.ReLU()(self.fc1(combined_output))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "base_station_models = []\n",
    "\n",
    "for base_station in range(num_base_stations):\n",
    "    # Instantiate CNN model\n",
    "    cnn_model = CNNModel(input_channels=3, output_size=512)  # Assuming RGB images\n",
    "    # Instantiate MobileViT model\n",
    "    mobilevit_model = MobileViTModel(input_channels=3, output_size=512)  # Assuming RGB images\n",
    "\n",
    "    # Instantiate the Hybrid model\n",
    "    hidden_layer_size = 512\n",
    "    output_size = 256\n",
    "    final_output_size = 256  # Assuming 10 classes for classification\n",
    "\n",
    "    # Instantiate the HybridModel\n",
    "    hybrid_model = HybridModel(cnn_model, mobilevit_model, hidden_layer_size, output_size, final_output_size)\n",
    "\n",
    "    optimizer = torch.optim.Adam(hybrid_model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_dataset = TensorDataset(torch.stack([load_image_data(index, base_station_folder='output_images') for index in train_index]), output_segments_train[base_station])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "\n",
    "\n",
    "    total_batches = len(train_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Training Base Station {base_station + 1}, Epoch {epoch + 1}\")\n",
    "        epoch_losses = []\n",
    "        for batch_idx, (batch_inputs, batch_targets) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            predictions = hybrid_model(batch_inputs)\n",
    "            loss = criterion(predictions, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_losses.append(loss.item())\n",
    "            # Print progress\n",
    "            #percent_complete = (batch_idx + 1) / total_batches * 100\n",
    "            #sys.stdout.write(f\"\\rProgress: [{int(percent_complete)}%]\")\n",
    "            #sys.stdout.flush()\n",
    "\n",
    "        #print()  # Move to the next line after completing an epoch\n",
    "        training_history[base_station].append(np.mean(epoch_losses))\n",
    "\n",
    "    base_station_models.append(hybrid_model)\n",
    "\n",
    "# Evaluation on the test set\n",
    "\n",
    "input_segments_test = torch.stack([load_image_data(index, base_station_folder='output_images') for index in test_index])\n",
    "output_segments_test = torch.tensor(Out_test)\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_targets in dataloader:\n",
    "            predictions = model(batch_inputs)\n",
    "            \n",
    "            # Ensure predictions and targets have the same shape\n",
    "            batch_size = batch_targets.size(0)\n",
    "            predictions = predictions.view(batch_size, -1)  # Flatten predictions\n",
    "            batch_targets = batch_targets.view(batch_size, -1)  # Flatten targets\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(predictions, batch_targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_station_losses = []\n",
    "# Evaluate each base station model\n",
    "for base_station, model in enumerate(base_station_models):\n",
    "    test_dataset = TensorDataset(input_segments_test, output_segments_test[:, base_station])  # Adjust the dimensions\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    test_loss = evaluate_model(model, test_dataloader)\n",
    "    base_station_losses.append(test_loss)\n",
    "    print(f\"Base Station {base_station + 1} Test Loss: {test_loss}\")\n",
    "\n",
    "# Calculate the mean of MSE for all base stations\n",
    "mean_mse = np.mean(base_station_losses)\n",
    "print(f\"Mean MSE across all Base Stations: {mean_mse}\")\n",
    "\n",
    "# Save the mean MSE to a CSV file\n",
    "mean_mse_df = pd.DataFrame({\"Mean_MSE\": [mean_mse]})\n",
    "mean_mse_df.to_csv(\"mean_mse_results.csv\", index=False)\n",
    "\n",
    "# Plotting the training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "for base_station, history in enumerate(training_history):\n",
    "    plt.plot(range(1, num_epochs + 1), history, label=f\"Base Station {base_station + 1}\")\n",
    "\n",
    "plt.title('Training History of Hybrid Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Set both the lower and upper y-axis limits\n",
    "plt.ylim(0.0005, plt.ylim()[1])\n",
    "\n",
    "# Save the figure as a PDF\n",
    "plt.savefig(\"training_history_plot.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "############ Attack the RF Beamforming Codeword Prediction Model ##########\n",
    "print(\"Attack\")\n",
    "\n",
    "def fgsm_attack(model, input_data, target_data, epsilon):\n",
    "    model.eval()\n",
    "    input_data.requires_grad = True\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "\n",
    "    # Calculate loss only for the specific base station\n",
    "    batch_size = output.size(0)\n",
    "    target_slice = target_data[:, 4*base_station:4*(base_station+1)]  # Slice target data for the specific base station\n",
    "\n",
    "    # Resize output tensor to match the shape of the target slice\n",
    "    output_resized = output[:, :target_slice.size(1)]\n",
    "\n",
    "    loss = nn.MSELoss()(output_resized, target_slice)\n",
    "\n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # FGSM attack\n",
    "    input_data_grad = input_data.grad.data\n",
    "    perturbed_input = input_data + epsilon * torch.sign(input_data_grad)\n",
    "\n",
    "    return perturbed_input\n",
    "\n",
    "# Choose an epsilon value for the attack\n",
    "# Choose an epsilon value for the attack\n",
    "epsilon = 0.5\n",
    "\n",
    "# Generate adversarial examples for the training set\n",
    "adversarial_examples_train = []\n",
    "for base_station, model in enumerate(base_station_models):\n",
    "    input_data = torch.stack([load_image_data(index, base_station_folder='output_images') for index in train_index]).clone().detach().requires_grad_(True)\n",
    "    target_data = output_segments_train[base_station].clone().detach()  # Target data for this base station\n",
    "\n",
    "\n",
    "    perturbed_input = fgsm_attack(model, input_data, target_data, epsilon)\n",
    "    \n",
    "    adversarial_examples_train.append(perturbed_input)\n",
    "\n",
    "# Evaluate the model on the adversarial examples generated from the training set\n",
    "adversarial_losses_train = []\n",
    "for base_station, model in enumerate(base_station_models):\n",
    "    adversarial_dataset_train = TensorDataset(adversarial_examples_train[base_station], output_segments_train[base_station])\n",
    "    adversarial_dataloader_train = DataLoader(adversarial_dataset_train, batch_size=32, shuffle=False)\n",
    "    adversarial_loss_train = evaluate_model(model, adversarial_dataloader_train)\n",
    "    adversarial_losses_train.append(adversarial_loss_train)\n",
    "    print(f\"Base Station {base_station + 1} Adversarial Train Loss: {adversarial_loss_train}\")\n",
    "\n",
    "# Calculate the mean of MSE for all base stations on adversarial examples generated from the training set\n",
    "mean_adversarial_mse_train = np.mean(adversarial_losses_train)\n",
    "print(f\"Mean Adversarial Train MSE across all Base Stations: {mean_adversarial_mse_train}\")\n",
    "\n",
    "# Save the mean Adversarial Train MSE to a CSV file\n",
    "mean_adversarial_mse_train_df = pd.DataFrame({\"Mean_Adversarial_Train_MSE\": [mean_adversarial_mse_train]})\n",
    "mean_adversarial_mse_train_df.to_csv(\"mean_adversarial_train_mse_results.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine original training data with adversarial examples\n",
    "original_inputs = torch.stack([load_image_data(index, base_station_folder='output_images') for index in train_index])\n",
    "original_targets = output_segments_train[base_station]\n",
    "adversarial_inputs = torch.cat(adversarial_examples_train, dim=0)\n",
    "adversarial_targets = output_segments_train[base_station]  # Assuming adversarial targets are the same as original targets\n",
    "\n",
    "# Resize adversarial inputs to match the size of original inputs\n",
    "adversarial_inputs = adversarial_inputs[:original_inputs.size(0)]  \n",
    "\n",
    "\n",
    "\n",
    "# Concatenate inputs and targets\n",
    "combined_inputs = torch.cat((original_inputs, adversarial_inputs), dim=0)\n",
    "combined_targets = torch.cat((original_targets, adversarial_targets), dim=0)\n",
    "\n",
    "# Create combined dataset and dataloader\n",
    "combined_train_dataset = TensorDataset(combined_inputs, combined_targets)\n",
    "train_dataloader = DataLoader(combined_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "#base_station_models = []\n",
    "total_batches = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Training Base Station {base_station + 1}, Epoch {epoch + 1}\")\n",
    "    epoch_losses = []\n",
    "    for batch_idx, (batch_inputs, batch_targets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = hybrid_model(batch_inputs)\n",
    "        loss = criterion(predictions, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    training_history[base_station].append(np.mean(epoch_losses))\n",
    "\n",
    "base_station_models.append(hybrid_model)\n",
    "\n",
    "# Evaluate the model on the adversarial examples generated from the training set\n",
    "adversarial_losses_train = []\n",
    "for base_station, model in enumerate(base_station_models):\n",
    "    adversarial_dataset_train = TensorDataset(input_segments_test, output_segments_test[:, base_station])  # Adjust the dimensions\n",
    "    adversarial_dataloader_train = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    adversarial_loss_train = evaluate_model(model, test_dataloader)\n",
    "    adversarial_losses_train.append(adversarial_loss_train)\n",
    "    print(f\"Base Station {base_station + 1} Adversarial Train Loss: {adversarial_loss_train}\")\n",
    "\n",
    "# Calculate the mean of MSE for all base stations on adversarial examples generated from the training set\n",
    "mean_adversarial_mse_train = np.mean(adversarial_losses_train)\n",
    "print(f\"Mean Adversarial Train MSE across all Base Stations: {mean_adversarial_mse_train}\")\n",
    "\n",
    "# Save the mean Adversarial Train MSE to a CSV file\n",
    "mean_adversarial_mse_train_df = pd.DataFrame({\"Mean_Adversarial_Train_MSE\": [mean_adversarial_mse_train]})\n",
    "mean_adversarial_mse_train_df.to_csv(\"mean_adversarial_train_mse_results.csv\", index=False)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5361c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
